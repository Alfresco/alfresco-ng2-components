name: "Upload build artifacts"
description: "Upload build artifacts"
inputs:
  packages:
    description: 'packages to cache across the current run'
    required: false
    type: string
  persistent-packages:
    description: 'packages to cache in s3'
    required: false
    type: string
  cache-key-suffix:
    description: 'cache key suffix'
    required: false
    type: string
    default: ''
runs:
  using: "composite"
  steps:
    - name: tar and upload current run cache artifacts
      shell: bash
      env:
       REMOTE_PATH: "adf/build-cache/${{ github.run_id }}"
      run: |
        packages=( $(echo ${{ inputs.packages }}) )
        for i in "${packages[@]}"; do
          echo "processing $i"
          tar czf $i.tar.gz $i
          echo "package size: $(du -h $i.tar.gz)"
          echo "uploading current run artifacts to ${REMOTE_PATH}/$i.tar.gz"
          aws s3 cp --no-progress $i.tar.gz s3://${S3_BUILD_BUCKET_SHORT_NAME}/${REMOTE_PATH}/$i.tar.gz
        done
    - name: tar and upload persistent cache artifacts
      shell: bash
      run: |
        HASH=$(cat $GITHUB_WORKSPACE/package-lock.json | shasum | head -c 40)
        REMOTE_PATH="adf/build-cache/${HASH}"
        if [ -n "${{ inputs.cache-key-suffix }}" ]; then
          REMOTE_PATH="${REMOTE_PATH}-${{ inputs.cache-key-suffix }}"
        fi
        packages=( $(echo ${{ inputs.persistent-packages }}) )
        for i in "${packages[@]}"; do
          tar czf $i.tar.gz $i
          du -h $i.tar.gz
          echo "pushing persistent cache to $REMOTE_PATH"
          aws s3 cp --no-progress $i.tar.gz s3://${S3_BUILD_BUCKET_SHORT_NAME}/${REMOTE_PATH}/$i.tar.gz
        done


